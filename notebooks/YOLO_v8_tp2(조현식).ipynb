{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "base_path = \"datasets/base\"\n",
    "label_path = \"datasets/label\"\n",
    "\n",
    "# jpg와 json 파일 리스트를 가져옵니다.\n",
    "jpg_files = [f for f in os.listdir(base_path) if f.endswith(\".jpg\")]\n",
    "json_files = [f for f in os.listdir(label_path) if f.endswith(\".json\")]\n",
    "\n",
    "# jpg와 json 파일 수가 같은지 확인합니다.\n",
    "assert len(jpg_files) == len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(jpg_files, json_files))\n",
    "random.shuffle(combined)\n",
    "jpg_files, json_files = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = len(jpg_files)\n",
    "\n",
    "train_size = int(0.7 * total_files)\n",
    "val_size = int(0.2 * total_files)\n",
    "\n",
    "train_jpgs = jpg_files[:train_size]\n",
    "val_jpgs = jpg_files[train_size:train_size+val_size]\n",
    "test_jpgs = jpg_files[train_size+val_size:]\n",
    "\n",
    "train_jsons = json_files[:train_size]\n",
    "val_jsons = json_files[train_size:train_size+val_size]\n",
    "test_jsons = json_files[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_path = \"datasets/train/base\"\n",
    "val_base_path = \"datasets/val/base\"\n",
    "test_base_path = \"datasets/test/base\"\n",
    "\n",
    "train_label_path = \"datasets/train/label\"\n",
    "val_label_path = \"datasets/val/label\"\n",
    "test_label_path = \"datasets/test/label\"\n",
    "\n",
    "# 폴더 생성\n",
    "for path in [train_base_path, val_base_path, test_base_path, train_label_path, val_label_path, test_label_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# 파일 이동\n",
    "for f in train_jpgs:\n",
    "    shutil.move(os.path.join(base_path, f), train_base_path)\n",
    "for f in train_jsons:\n",
    "    shutil.move(os.path.join(label_path, f), train_label_path)\n",
    "\n",
    "for f in val_jpgs:\n",
    "    shutil.move(os.path.join(base_path, f), val_base_path)\n",
    "for f in val_jsons:\n",
    "    shutil.move(os.path.join(label_path, f), val_label_path)\n",
    "\n",
    "for f in test_jpgs:\n",
    "    shutil.move(os.path.join(base_path, f), test_base_path)\n",
    "for f in test_jsons:\n",
    "    shutil.move(os.path.join(label_path, f), test_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def process_json(data, use_center_format=False):\n",
    "    \"\"\" 주어진 JSON 데이터에서 shape_type이 bbox인 항목의 area_code와 points를 반환합니다. \"\"\"\n",
    "    output_str = ''\n",
    "    image_width = data['description']['imageWidth']\n",
    "    image_height = data['description']['imageHeight']\n",
    "    \n",
    "    for category, annotations in data['annotations'].items():\n",
    "        for annotation in annotations:\n",
    "            if annotation['shape_type'] == 'bbox':\n",
    "                # bbox에서 중심점과 너비/높이를 계산\n",
    "                left = annotation['points'][0]\n",
    "                top = annotation['points'][1]\n",
    "                width = annotation['points'][2]\n",
    "                height = annotation['points'][3]\n",
    "\n",
    "\n",
    "                #if use_center_format:\n",
    "                x = (left + width/2) /image_width\n",
    "                y = (top + height/2) /image_height\n",
    "                width /= image_width\n",
    "                height /= image_height\n",
    "                points = [x, y, width, height]\n",
    "\n",
    "                # else:\n",
    "                #     # points 값을 스케일링\n",
    "                #     points = [\n",
    "                #         left / image_width,\n",
    "                #         top / image_height,\n",
    "                #         (left + width) / image_width,\n",
    "                #         (top + height) / image_height\n",
    "                #     ]\n",
    "\n",
    "                code = int(annotation.get('area_code', annotation.get('PM_code', '')))\n",
    "                code -= 13\n",
    "                \n",
    "                if code == 21:\n",
    "                    continue\n",
    "\n",
    "                if code > 21:\n",
    "                    code -= 1\n",
    "                #if code not in [0, 7, 15]:\n",
    "                output_str += f\"{code} {' '.join(map(str, points))}\\n\"\n",
    "    return output_str\n",
    "\n",
    "# JSON 파일이 있는 폴더 경로\n",
    "source_folder = 'datasets/train/label'  # 이곳에 JSON 파일이 있는 폴더 경로를 입력하세요.\n",
    "\n",
    "# 결과 텍스트 파일들을 저장할 폴더 경로\n",
    "destination_folder = 'datasets/train/base'  # 이곳에 결과 텍스트 파일을 저장할 폴더 경로를 입력하세요.\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# 폴더 내의 모든 파일들을 순회\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        json_path = os.path.join(source_folder, filename)\n",
    "        \n",
    "        # JSON 파일 읽기\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            \n",
    "            # JSON 데이터 처리\n",
    "            result = process_json(data)\n",
    "            \n",
    "            # 결과를 지정된 경로의 text 파일로 저장\n",
    "            txt_filename = filename.replace('.json', '.txt')\n",
    "            txt_path = os.path.join(destination_folder, txt_filename)\n",
    "            with open(txt_path, 'w') as txt_file:\n",
    "                txt_file.write(result)\n",
    "\n",
    "print(\"All JSON files have been processed and written to text files in the destination folder!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "data = {'path' : '../ultralytics/datasets',\n",
    "        'train' : 'D:/codestates/Team Project 2/ultralytics/datasets/train/base',\n",
    "        'val' : 'D:/codestates/Team Project 2/ultralytics/datasets/val/base',\n",
    "        'test' : 'D:/codestates/Team Project 2/ultralytics/datasets/test/base',\n",
    "        'names' : ['오토바이', '오토바이_보행자도로 통행위반',\n",
    "              '오토바이_안전모 미착용', '오토바이_무단횡단', '오토바이_신호위반', '오토바이_정지선위반',\n",
    "              '오토바이_횡단보도 주행위반', '자전거', '자전거 캐리어', '자전거_보행자도로 통행위반',\n",
    "              '자전거_안전모 미착용', '자전거_무단횡단', '자전거_신호위반', '자전거_정지선위반',\n",
    "              '자전거_횡단보도 주행위반', '킥보드', '킥보드 캐리어', '킥보드_보행자도로 통행위반',\n",
    "              '킥보드_안전모 미착용', '킥보드_무단횡단', '킥보드_신호위반', '킥보드_횡단보도 주행위반',\n",
    "              '킥보드_동승자 탑승위반'],\n",
    "        'nc' : 23 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "with open('sample.yaml', 'r') as f:\n",
    "    sample_yaml = yaml.safe_load(f)\n",
    "    display(sample_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "# import torch\n",
    "# device = torch.device(\"cuda\")\n",
    "model = YOLO('D:/codestates/Team Project 2/ultralytics/runs/detect/train75_v8s_60epoch/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data='sample.yaml', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO('yolov8s.pt')  # load an official model\n",
    "model = YOLO('D:/codestates/Team Project 2/ultralytics/runs/detect/train70_v8s_50epoch/weights/best.pt')  # load a custom model\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mAP50-95:\", metrics.box.map)\n",
    "print(\"mAP50:\", metrics.box.map50)\n",
    "print(\"mAP75:\", metrics.box.map75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "#\n",
    "# Load a model\n",
    "#model = YOLO('yolov8n.pt')  # load an official model\n",
    "model = YOLO('D:/codestates/Team Project 2/ultralytics/runs/detect/train75_v8s_60epoch/weights/best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model('D:/codestates/Team Project 2/ultralytics/sample2.mp4',stream=True)  # predict on an image\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    #masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    #keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    #probs = result.probs  # Probs object for classification outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('D:/codestates/Team Project 2/ultralytics/runs/detect/train75_v8s_60epoch/weights/best.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"D:/codestates/Team Project 2/ultralytics/vidio/input/sample9.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "out = cv2.VideoWriter('output_video9.avi', fourcc, fps, frame_size)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Save the annotated frame to the video\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture, video writer object and close the display window\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
